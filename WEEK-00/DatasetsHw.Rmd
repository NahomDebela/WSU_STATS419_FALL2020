---
title: "R Project"
author: "Nahom Debela"
date: "4/3/2020"
output: pdf_document
---


											
#transposes given matrix											
transposeMatrix = function(mat)
  {
  t(mat);
  }

transposeMatrix(myMatrix)

#--------------------------------------------------------------
#Q1
rotate90 = function(mat)
{
t(apply(mat,2,rev))
}

#Rotate by 90 degrees one by one
myMatrix
matrix90 <- rotate90(myMatrix) 
matrix180 <- rotate90(matrix90) 
matrix270 <- rotate90(matrix180) 

myMatrix
matrix90
matrix180
matrix270
#--------------------------------------------------------------
#Q2
pairs(iris[1:4], pch = 21, bg = c("red", "green3", "blue") [unclass(iris$Species)])
#--------------------------------------------------------------
#Q4

library(lubridate)

# Deleted column V00
my_data <- read.table("personality-raw.txt", header = TRUE, sep = "|");

my_data$V00 <- NULL

my_data
head(my_data)

#Strips time apart so we can parse it
date = strptime(my_data$date_test, format = '%m/%d/%Y %H:%M');

new_df = cbind(my_data, date);

#Parse the date 

yr <- year(date);
new_df$year <- yr

wk <- week(date);
new_df$week <- wk

new_df$date_test <- NULL


#sort dataframe by date and week, descending
new_df <- new_df[
 order(-new_df$year,-new_df$week),]
 
# Delete duplicate rows by md5_email column
new_df <- unique(new_df, by = "md5_email")

#write a pipeline delimited dataframe to text
write.table(new_df, file = "personality-clean.txt", sep = "|")

dim(my_data)
dim(new_df)
#--------------------------------------------------------------
#Q5

library(matrixStats)

#doSummary 
doSummary <- function(data)
{
len <- length(data)
cat("length", len, "\n")

num_na <- sum(is.na(data))
cat("Number of NA", num_na, "\n")

mean_data <- 	rowMeans(data[sapply(data, is.numeric)]) 
cat("Mean", mean_data, "\n")

mshafer_data_dropped <- data
mshafer_data_dropped[,1] <- NULL
mshafer_data_dropped[,61] <- NULL
mshafer_data_dropped[,61] <- NULL
mshafer_data_dropped[,61] <- NULL
mshafer_data_dropped <- as.numeric(mshafer_data_dropped[1,])
median_data <- 	median(mshafer_data_dropped) 
cat("Median",median_data, "\n")

print("hello")

mode_data <- doMode(data)
mode_data<- as.numeric(mode_data)
cat("Mode", mode_data, "\n")


mshafer_data_dropped2 <- data
mshafer_data_dropped2[,1] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2 <- as.numeric(mshafer_data_dropped2[1,])
standard_dev <- sd(mshafer_data_dropped2)
variance <- var(mshafer_data_dropped2)
cat("Variance", variance, "\n")
cat("Standard Deviation", standard_dev)

}

#------------------------------------------------------------

mshafer_data <- new_df[1,]
mshafer_data

doSummary(mshafer_data)

#------------------------------------------------------------

#sampleVariance 
doVariance <- function(data, method)
{
  if (method == "naive")
    {
      n = sum = sumsq = 0
      for (i in 1:length(data))
      {
        n <- n + 1
        sum <- sum + data[i]
        sumsq <- sumsq + i * i
      }
      variance <- (sumsq − (sum * sum) / n) / (n − 1)
    }
    else  
    {
           # two - pass algorithim
          n = sum1 = sum2 = 0

          for (i in 1:length(data))
            {
              a <- a + 1
              sum1 <- sum1 + data[i]
            }
          mean = sum1 / n
          for (i in 1:length(data))
          `{
            sum2 = sum2 + ( (i - mean) * (i - mean) )
         ` }
          variance <- sum2 / (n - 1)
    }
    
#doMode

doMode <- function(d)
{
unique_n <- unique(d)
unique_n[which.max(tabulate(match(d, unique_n)))]
}

#------------------------------------------------------------
#Q5.2    

mshafer_data <- new_df[1,]
mshafer_data

zscore_plot <- function(data)
{
mshafer_data_dropped2 <- data
mshafer_data_dropped2[,1] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2[,61] <- NULL
mshafer_data_dropped2 <- as.numeric(mshafer_data_dropped2[1,])
zscore <- (mshafer_data_dropped2 - mean(mshafer_data_dropped2)) / sd(mshafer_data_dropped2)
plot(mshafer_data_dropped2,zscore)
return(zscore)
}

mshafer_data <- new_df[1,]
mshafer_data


zscore_plot(mshafer_data)

doSummary(mshafer)

#------------------------------------------------------------

#Q6
library(rvest);	
library(stringr);	

grabFilmInfoFromFilmsPage


grabFilmInfoFromFilmsPage = function(page)
	{
	# 50 elements
	# # title = id = rank = year = rating = minutes = genre = votes = metascore = desc = millions
	
	movies = page %>%
		html_nodes(".mode-detail");
		
	
		
	pagecount = length(movies);
	
	result = data.frame( 			matrix(ncol = 11,nrow = pagecount) );
	# a matrix-type form with lots of NA values ...
	
	colnames(result) = c("rank", "title", "ttid", "year", "rated", "minutes", "genre", "ratings", "metacritic", "votes", "millions"); 
				
	
	for(i in 1:pagecount)
		{
		movie = movies[i];
		
		rank = movie %>%
			html_node(".lister-item-index") %>%
			html_text() %>%
			as.numeric();
		result$rank[i] = rank;
			
		title = movie %>%
			html_node(".lister-item-header a") %>%
			html_text();
		result$title[i] = title;
			
		ttid = movie %>%
			html_node(".lister-item-header a") %>%
			html_attr("href");
			
			temp = strsplit(ttid,"/",fixed=T);
		ttid = temp[[1]][3];
		result$ttid[i] = ttid;
		
		year = movie %>%
			html_node(".lister-item-year") %>%
			html_text();
		year = cleanupYear(year);
		result$year[i] = year;
		
		rated = movie %>%
			html_node(".certificate") %>%
			html_text();
		result$rated[i] = rated;
			
		minutes = movie %>%
			html_node(".runtime") %>%
			html_text();
		minutes = cleanupMinutes(minutes);
		result$minutes[i] = minutes;		
		
		genre = movie %>%
			html_node(".genre") %>%
			html_text();
		genre = str_trim(genre);
		result$genre[i] = genre;
		
		ratings = movie %>%
			html_node("div .rating-list") %>%
			html_attr("title");
				temp = strsplit(ratings,"/",fixed=T);
				temp = gsub("Users rated this","",temp[[1]][1],fixed=T);	
				temp = str_trim(temp);
		ratings = as.numeric(temp);
		result$ratings[i] = ratings;
		
		metacritic = movie %>%
			html_node(".ratings-metascore span") %>%
			html_text();
		metacritic = as.numeric(str_trim(metacritic));
		result$metacritic[i] = metacritic;
		
		# para ... +5 EASTER EGG ...
		
		info = movie %>%
			html_nodes(".lister-item-content p span") %>%
			html_text();
			
		votes = as.numeric(gsub(",","",info[8],fixed=T));
		result$votes[i] = votes;
		
		millions = cleanupMillions(info[11]);
		result$millions[i] = millions;			
		}
		
		#str(result);
		
	result;
	}
	
	
cleanupMillions = function(millions)
	{
	millions = gsub('$','',millions, fixed=T);
	millions = gsub('M','',millions, fixed=T);
	
	millions = as.numeric(millions);
	millions;
	}
	
cleanupMinutes = function(minutes)
	{
	minutes = gsub('min','',minutes, fixed=T);
	
	minutes = as.numeric(minutes);
	minutes;
	}
	
cleanupYear = function(year)
	{
	year = gsub('(','',year, fixed=T);
	year = gsub(')','',year, fixed=T);
	year = gsub('I','',year, fixed=T);
	year = as.numeric(year);
	year;
	}

grabNameFromFilmsPage = function(page)
	{
	name = page %>%
		html_node(".header") %>%
		html_text();
		
		name = gsub("Most Rated Feature Films With","",name,fixed=T);
		name = str_trim(name);
	
	name;
	}

	
grabFilmCountFromFilmsPage = function(page)
	{
	totalcount = page %>%
		html_nodes(".desc") %>%
		html_text();
		
		temp = strsplit(totalcount,"of",fixed=T);
		temp2 = strsplit(temp[[1]][2],"titles", fixed=T);
		
		totalcount = str_trim(temp2[[1]][1]);
		totalcount = as.numeric(totalcount);
		
		temp2 = strsplit(temp[[1]][1],"to", fixed=T);
		
		pagecount = str_trim(temp2[[1]][2]);
		pagecount = as.numeric(pagecount);
		
	result = list();
	
	result$totalcount = totalcount;
	result$pagecount = pagecount;
	
	result;
	}
		
	
#------------------

  nmid = "nm0000226";
 	will = grabFilmsForPerson(nmid);
 	plot(will$movies.50[,c(1,6,7:10)]);
  	boxplot(will$movies.50$millions);
		widx =  which.max(will$movies.50$millions);
	will$movies.50[widx,];
		summary(will$movies.50$year);  # bad boys for life ... did data change?

   nmid = "nm0000243";
 	denzel = grabFilmsForPerson(nmid);
 	plot(denzel$movies.50[,c(1,6,7:10)]);
  	boxplot(denzel$movies.50$millions);
		didx =  which.max(denzel$movies.50$millions);
	denzel$movies.50[didx,];
		summary(denzel$movies.50$year);
	
	par(mfrow=c(1,2));
	boxplot(will$movies.50$millions, main=will$name, ylim=c(0,360), ylab="Raw Millions" );
	boxplot(denzel$movies.50$millions, main=denzel$name, ylim=c(0,360), ylab="Raw Millions" );
	
	par(mfrow=c(1,1));
	
	# https://www.in2013dollars.com/us/inflation/2000?endYear=1982&amount=100
	# create variable $millions.2000 to convert all money to 2000 dollars ... based on year 


grabFilmsForPerson = function(nmid)
	{
	url = paste("https://www.imdb.com/filmosearch/?explore=title_type&role=",nmid,"&ref_=filmo_ref_typ&sort=num_votes,desc&mode=detail&page=1&title_type=movie", sep="");
	
	page1 = read_html(url);
	result = list();
	## useful for other data purposes
	result$nmid = nmid;
	
	## name of person
	result$name = grabNameFromFilmsPage(page1);
	result$countfilms = grabFilmCountFromFilmsPage(page1);
	
	result$movies.50 = grabFilmInfoFromFilmsPage(page1);
	
	
	
	
	##  parallel format ...
	# ranks = page1 %>%
		# html_nodes(".lister-item-index") %>%
		# html_text() %>%
		# as.numeric();	
	
	# ranks;
	
	# years = page1 %>%
		# html_nodes(".lister-item-year") %>%
		# html_text();
		
		# years = gsub('(','',years, fixed=T);
		# years = gsub(')','',years, fixed=T);
		# years = gsub('I','',years, fixed=T);
		# years = as.numeric(years);
		
	# titles = page1 %>%	
		# html_nodes(".lister-item-header a") %>%
		# html_text();
		
	# titles;
	
	
	result;
	}



getRate2020<-function(x)   #use m to find the percent increase from that m position in inflation
{                #to end of inflation table ... this works!
  final<-c()

  for (i in x) 
  {
    adjust<-cumprod(inflation$adjusted[i:101])
    last<-last(adjust)
    final<-append(final, last)
  }
  final
}


#------------------------------------------------------------

}

```

